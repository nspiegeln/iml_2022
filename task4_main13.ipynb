{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task4_main13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoyOpL8dWMOpW9wXQ2/Z0M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nspiegeln/iml_2022/blob/main/task4_main13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf5W8dV5KiTn"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"task4_main8.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1uPxuWvUseQEoYNbB9dtpwKwMsNZCjk-9\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses, metrics\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path = \"gdrive/MyDrive/task4/\"\n",
        "df_train= pd.read_csv(path + \"train_features.csv\")\n",
        "df_train_labels= pd.read_csv(path + \"train_labels.csv\")\n",
        "df_pretrain= pd.read_csv(path +\"pretrain_features.csv\")\n",
        "df_pretrain_labels= pd.read_csv(path +\"pretrain_labels.csv\")\n",
        "df_test= pd.read_csv(path +\"test_features.csv\")\n",
        "\n",
        "df_train_values = df_train.iloc[:,2::]\n",
        "df_pretrain_values = df_pretrain.iloc[:,2::]\n",
        "\n",
        "df_train_lab = df_train_labels.iloc[:,1]\n",
        "df_pretrain_lab = df_pretrain_labels.iloc[:,1]\n",
        "\n",
        "train = df_train_values.values #dataset with known homo-lumo gap\n",
        "pretrain = df_pretrain_values.values #dataset with known lumo value\n",
        "\n",
        "train_labels = df_train_lab.values\n",
        "pretrain_labels = df_pretrain_lab.values\n",
        "\n",
        "x_pretrain, x_pretest, y_pretrain, y_pretest = train_test_split(pretrain, pretrain_labels, test_size = 0.1)\n",
        "print(x_pretrain.shape[0], x_pretrain.shape[1])\n",
        "print(x_pretest.shape[0], x_pretest.shape[1])\n",
        "\n",
        "#get device\n",
        "def get_default_device():\n",
        "    \"\"\"Picking GPU if available or else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "# PRE-PROCESSING of features according to autoencoder\n",
        "# pre-train set\n",
        "\n",
        "#hyperparameters\n",
        "dim = 200\n",
        "epochs = 100         #resuls still decrease after epoch 100, @epoch=100 loss=3.4e-3\n",
        "batch_size = 64\n",
        "\n",
        "# create encoder and decoder to reduce dimensionality of features\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(500, activation='relu'),\n",
        "      layers.Dense(200, activation='relu'),\n",
        "    ])\n",
        "    self.trainor = tf.keras.Sequential([\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      \n",
        "    ])\n",
        "    self.predictor = tf.keras.Sequential([\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(50, activation='relu'),\n",
        "      layers.Dense(1),\n",
        "    ])                                     \n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    trained = self.trainor(encoded)\n",
        "    predicted = self.predictor(trained)\n",
        "    return predicted\n",
        "\n",
        "autoencoder = Autoencoder(dim)\n",
        "sgd = SGD(learning_rate=0.1, decay=0.9, momentum=0.9) #changed decay from 1e-2 to 0.9 loss = 3.5e-3\n",
        "autoencoder.compile(optimizer='sgd', loss=losses.MeanSquaredError())\n",
        "\n",
        "autoencoder.fit(x_pretrain, y_pretrain, epochs=epochs, batch_size = batch_size, shuffle=True, validation_data=(x_pretest, y_pretest))\n",
        "\n",
        "y_predpretrain = autoencoder.predict(x_pretrain)\n",
        "\n",
        "# Transfer learning to HOMO-LUMO gap learning\n",
        "# freeze everything but last layer\n",
        "for layer in autoencoder.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# autoencoder.encoder.summary()\n",
        "# autoencoder.trainor.summary()\n",
        "# autoencoder.predictor.summary()\n",
        "\n",
        "dim = 1\n",
        "epochs = 800   #loss decreases to loss=6.8e-3 after 1000 epochs\n",
        "class AutoencoderNew(Model):\n",
        "  def __init__(self, dim):\n",
        "    super(AutoencoderNew, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      autoencoder,\n",
        "      layers.Dense(50, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(200, activation='relu'),\n",
        "      layers.Dense(200, activation='relu'),\n",
        "      layers.Dense(200, activation='relu'),\n",
        "      layers.Dense(200, activation='relu'),\n",
        "      layers.Dense(200, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(50, activation='relu'),\n",
        "      layers.Dense(1),\n",
        "    ])                                    \n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    return encoded\n",
        "\n",
        "model = AutoencoderNew(dim)\n",
        "\n",
        "sgd = SGD(learning_rate=0.1, decay=0.9, momentum=0.9)\n",
        "\n",
        "model.compile(optimizer='sgd', loss=losses.MeanSquaredError())\n",
        "model.fit(train, train_labels, epochs=epochs, shuffle=True)\n",
        "\n",
        "#predict homolumo gap for testset\n",
        "x_test = df_test.iloc[:,2::]\n",
        "id_test = df_test.iloc[:,0]\n",
        "\n",
        "y_test = model.predict(x_test)\n",
        "\n",
        "#export solution\n",
        "df_evaltest = pd.DataFrame(y_test, columns = ['y'])\n",
        "df_evaltest.insert(0, 'Id', id_test)\n",
        "df_evaltest.to_csv('solutiontot8.csv', index=False, index_label=False, encoding = 'utf-8')"
      ]
    }
  ]
}