{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task3_main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOj25lY1iLXcMPgC+Gvekx5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nspiegeln/iml_2022/blob/main/task3_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ma9PbvePscU"
      },
      "outputs": [],
      "source": [
        "#load data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import image\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "o_09Ki4_P9VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('train_triplets.txt') as f:\n",
        "    train_id = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "with open ('test_triplets.txt') as f:\n",
        "    test_id = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "train_id, val_id = train_test_split(train_id, test_size = 0.1, random_state = 42)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_id, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_id, batch_size=32)\n",
        "valloader = torch.utils.data.DataLoader(val_id, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "lGtfQrf2QIUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.densenet121(pretrained=True ) \n",
        "criterion = nn.TripletMarginLoss(margin=1,p = 2.0, reduce =None, reduction='mean')\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.0003)"
      ],
      "metadata": {
        "id": "yTPo9GpnQKlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('bn1',nn.BatchNorm1d(500)),\n",
        "                          ('relu1',nn.ReLU(inplace=True)),\n",
        "                        #   ('drop1',nn.Dropout(p=0.5)),\n",
        "                          ('fc2', nn.Linear(500, 1000)),\n",
        "                          ('output', nn.Linear(1000, 10000))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier\n",
        "\n",
        "epochs = 10\n",
        "print_every = 40\n",
        "steps = 0\n",
        "\n",
        "model.to('cuda')"
      ],
      "metadata": {
        "id": "n-_X23htQO2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(triplet_string, train_transforms):\n",
        "    ids = triplet_string.split()\n",
        "    image_nr1 = ids[0]\n",
        "    image_nr2 = ids[1]\n",
        "    image_nr3 = ids[2]\n",
        "\n",
        "    pre_img1 = Image.open(r'food/' + image_nr1 + '.jpg')\n",
        "    pre_img2 = Image.open(r'food/' + image_nr2 + '.jpg')\n",
        "    pre_img3 = Image.open(r'food/' + image_nr3 + '.jpg')\n",
        "\n",
        "    img1 = train_transforms(pre_img1)\n",
        "    img2 = train_transforms(pre_img2)\n",
        "    img3 = train_transforms(pre_img3)\n",
        "\n",
        "    return img1, img2, img3, pre_img1, pre_img2 ,pre_img3"
      ],
      "metadata": {
        "id": "DsrmdOw3QQk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_gen(labels,train_transforms):\n",
        "    batch_A = torch.zeros((len(labels),3,224,224))\n",
        "    batch_B = torch.zeros_like(batch_A)\n",
        "    batch_C = torch.zeros_like(batch_A)\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        A,P,N,a,p,n = get_image(labels[i],train_transforms)\n",
        "        batch_A[i,:,:,:] = A\n",
        "        batch_B[i,:,:,:] = P\n",
        "        batch_C[i,:,:,:] = N\n",
        "    \n",
        "    # #cast to tensor\n",
        "    # batch_A = torch.from_numpy(batch_A)\n",
        "    # batch_B = torch.from_numpy(batch_B)\n",
        "    # batch_C = torch.from_numpy(batch_C)\n",
        "\n",
        "    return batch_A, batch_B, batch_C"
      ],
      "metadata": {
        "id": "4on_Kk6iQTGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(epochs):\n",
        "    sum_train_loss = 0\n",
        "    training_loss = 0\n",
        "    validation_loss = 0\n",
        "    for inputs, labels in enumerate(trainloader):\n",
        "        steps +=1\n",
        "        \n",
        "        batch_A, batch_B, batch_C= batch_gen(labels, train_transforms)\n",
        "        batch_A, batch_B, batch_C = batch_A.to('cuda'), batch_B.to('cuda'), batch_C.to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output1 = model.forward(batch_A)\n",
        "        output2 = model.forward(batch_B)\n",
        "        output3 = model.forward(batch_C)\n",
        "\n",
        "        training_loss = criterion(output1,output2,output3)\n",
        "\n",
        "        # if verbose:\n",
        "        #     plt.figure()\n",
        "        #     f,axarr = plt.subplots(1,3)\n",
        "        #     axarr[0].imshow(img1_o)\n",
        "        #     axarr[0].set_title('image A: ' + image_nr1)\n",
        "        #     axarr[1].imshow(img2_o)\n",
        "        #     axarr[1].set_title('image B: ' + image_nr2)\n",
        "        #     axarr[2].imshow(img3_o)\n",
        "        #     axarr[2].set_title('image C: ' + image_nr3)\n",
        "        #     f.suptitle('error:{}'.format(loss))\n",
        "\n",
        "\n",
        "        training_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sum_train_loss += training_loss.item()\n",
        "\n",
        "    \n",
        "    \n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
        "            \"Loss: {:.4f}\".format(sum_train_loss/print_every))\n",
        "            sum_train_loss = 0\n",
        "        print('training loss per batch: {}'.format(training_loss))\n",
        "\n",
        "    print('validation started')\n",
        "    \n",
        "    model.eval()\n",
        "    for inputs, labels in enumerate(valloader):\n",
        "        steps +=1\n",
        "        \n",
        "        batch_A, batch_B, batch_C= batch_gen(labels, train_transforms)\n",
        "        batch_A, batch_B, batch_C = batch_A.to('cuda'), batch_B.to('cuda'), batch_C.to('cuda')\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output1 = model(batch_A)\n",
        "            output2 = model(batch_B)\n",
        "            output3 = model(batch_C)\n",
        "\n",
        "            validation_loss = criterion(output1,output2,output3)\n",
        "\n",
        "        print('validation loss per batch: {}'.format(validation_loss))\n"
      ],
      "metadata": {
        "id": "r2MYFGFNQZ_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(batch_A,batch_B,batch_C):   \n",
        "    predictions = np.zeros((batch_A.shape[0],1))\n",
        "    with torch.no_grad():\n",
        "        output1 = model(batch_A)\n",
        "        output2 = model(batch_B)\n",
        "        output3 = model(batch_C)\n",
        "        loss = criterion2(output1,output2,output3)\n",
        "\n",
        "        for i in range(len(loss)):\n",
        "            \n",
        "            if loss[i].item() == 0:\n",
        "                predictions[i] = 1\n",
        "            else:\n",
        "                predictions[i] = 0\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "WXhUVdN4QavN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firstIteration = True\n",
        "for inputs, labels in enumerate(testloader):\n",
        "    # for triplets in labels:\n",
        "    #     img1, img2, img3,img1_o,img2_o,img3_o = get_image(triplets, test_transforms)\n",
        "    #     img1, img2, img3 = img1.to('cuda'), img2.to('cuda'), img2.to('cuda'),\n",
        "\n",
        "    batch_A, batch_B, batch_C= batch_gen(labels, test_transforms)\n",
        "    batch_A, batch_B, batch_C = batch_A.to('cuda'), batch_B.to('cuda'), batch_C.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_pred=predict(batch_A,batch_B,batch_C)\n",
        "        # predictions1 = np.append(batch_pred)\n",
        "        \n",
        "    if firstIteration:\n",
        "        predictions2 = batch_pred\n",
        "        firstIteration = False\n",
        "\n",
        "    \n",
        "    else:\n",
        "        predictions2= np.concatenate((predictions2,batch_pred),axis=0)"
      ],
      "metadata": {
        "id": "Y1b8jI1gQdkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions2\n",
        "predictions_tot = predictions.reshape((-1,1))\n",
        "predictions_tot = np.rint(predictions_tot)\n",
        "#with open('solutions.csv', 'w', newline='') as f:\n",
        "#    writer=csv.writer(f)\n",
        "#    writer.writerows(predictions2)\n",
        "np.savetxt('solutions.csv', predictions_tot, fmt='%s')\n",
        "\n",
        "# cast to data frame\n",
        "import pandas as pd\n",
        "\n",
        "df_pred = pd.DataFrame(np.squeeze(predictions_tot))\n",
        "df_pred.to_csv('solutions.csv', index=False, encoding='utf-8',index_label=None)"
      ],
      "metadata": {
        "id": "3CV_zbnhQgQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}